# ARE YOU A COMPUTER? üñ•Ô∏è
This Reddit bot is designed to ask the question "Are you a computer?" You may consider expanding its functionality by implementing a list of subreddits where bot interactions are common.

## Getting started
Create a new env: `python -m venv _env_bot`

Activate the env: `source _env_bot/bin/activate`

Now we can use python and pip as usual.

Install all dependencies: `pip install -r requirements.txt`

Create a new reddit bot under: https://www.reddit.com/prefs/apps

Fill in your `.env`

Run `bot.py`

## Context
In 1986, Howard Rheingold almost jokingly posted a question on the first online social network called ‚ÄúThe Well.‚Äù His concern about removing a tick from his daughter's scalp was answered within minutes. This experience led him to write the book The Virtual Community. The book presents a disturbing yet accurate dystopia of the potential development of the internet if we are not cautious. We may be facing this dystopia now.

In the late 2010s, a post emerged on one of the internet's dark corners, 4chan, proclaiming the internet dead and pointing to 2016 as its final year. The so-called ‚ÄúDead Internet Theory,‚Äù a conspiracy theory, posits that almost all content creation on the internet and its social media platforms is done by bots. The thesis is that certain actors use these bots to manipulate human audiences. While we should approach conspiracy theories with caution, there are noticeable similarities to today's online experience.


Interestingly, bot exposure affects perceptual biases and may influence our desire to regulate social bots (Yan et al., 2023). The perception of the percentage of social bots on the internet increases after exposure. The study also found that participants' confidence in recognizing such bots decreases after their first exposure to them. Additionally, exposure leads participants to favor stronger regulation of social bots. Policy-based regulation is preferred over self-regulation by the companies that provide our social media platforms (Yan et al., 2023). This might be a shimmer of hope, as it exaggerates our experience and perception of bots and could drive quicker regulation.

One must note that the term "bot" is not well-defined. There is no specific sophistication level an automated machine must reach to be called a bot. The distinction between a so-called good bot and a bad bot often hinges on their adherence to their ultimate goals.

There are, however, studies calculating the percentage of such "black sheep." Devastatingly, it lies at 30%, according to the Bad Bot Report conducted by Imperva in 2023 (Imperva, 2023).

Looking back at one of the first social bots, ELIZA, developed by Joseph Weizenbaum in the 1960s, we see the roots of our current concerns with automated interactions. ELIZA was designed to simulate a psychotherapist, responding to users' queries with a seemingly empathetic touch. Despite its rudimentary algorithm, which could only reflect user inputs in the form of generic questions or responses, users often anthropomorphized ELIZA as a genuine conversational partner. This phenomenon highlighted an intriguing aspect of human interaction with bots: the tendency to attribute human-like characteristics to even the simplest forms of artificial intelligence.

The parallels between ELIZA and today's sophisticated bots are striking. Just as users in the 1960s quickly ascribed human qualities to ELIZA, modern internet users can fall prey to the illusion of genuine engagement with increasingly sophisticated bots. The evolving nature of these bots, whether driven by AI or less advanced scripting, has made them more adept at mimicking human interaction, blurring the lines between authentic human discourse and automated responses.