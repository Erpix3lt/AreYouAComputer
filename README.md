# ARE YOU A COMPUTER? üñ•Ô∏è
This Reddit bot is designed to ask the question "Are you a computer?" You may consider expanding its functionality by implementing a list of subreddits where bot interactions are common.

## Getting started
Create a new env: `python -m venv _env_bot`

Activate the env: `source _env_bot/bin/activate`

Now we can use python and pip as usual.

Install all dependencies: `pip install -r requirements.txt`

Create a new reddit bot under: https://www.reddit.com/prefs/apps

Fill in your `.env`

Run `bot.py`

## Context
In 1986 Howard Rheingold almost jokingly posted a question on the first online social networks called: ‚ÄúThe Well‚Äù. His concern about removing a tick from his daughter's scalp was answered within minutes. This would later lead him to write the book ‚ÄúThe Virtual Community‚Äù. Disturbingly the book paints an accurate dystopia of where the internet can develop if we are not cautious. We may be facing this dystopia now. 

In the late 2010s a post emerged on one of the internet's dark corners, 4chan. It pronounced the internet dead and pointed its last breaths towards 2016. The so-called ‚ÄúDead Internet Theory‚Äù, a conspiracy theory, has both a setup and a thesis. The setup being, that almost all content creation on the internet and its social media platforms is done by bots. The thesis being that certain actors are using these bots to manipulate the human audiences. As with any conspiracy theory, one must be cautious, but there are strange similarities to today's online experience.

‚Äî


Interestingly enough bot exposure affects perceptual biases and may influence our desire to regulate social bots (Yan et al., 2023). The perception of the total percentage of social bots on the internet increases after exposure. The study also found that participants' confidence in recognising such bots decreases after their first exposure to them. Exposure also leads participants to favor stronger regulation of social bots. Policy-based regulation is preferred to self-regulation by the companies that provide our social media platforms (Yan et al., 2023). This might be a shimmer of hope, as it exaggerates our experience and perception of bots and will possibly drive us to quicker regulation. 
One has to point out that the word bot is not very well defined. There is no sophistication level an automated machine has to reach in order to be called a bot. There is no clear line between a so-called good bot and a bad bot other than the level of correctness towards their ultimate goal. 
There are, however, studies calculating the percentage of such black sheep. Devastatingly, it lies at 30%, according to the Bad Bot Report conducted by Imperva in 2023 (Imperva, 2023).
Looking back on one of the first social bots, ELIZA, developed by Joseph Weizenbaum in the 1960s, we can already see the seeds of our current concerns with automated interactions. ELIZA was designed to simulate a psychotherapist, responding to users' queries with a seemingly empathetic touch. Despite its rudimentary algorithm, which could only reflect user inputs back in the form of generic questions or responses, users often anthropomorphized ELIZA as a genuine conversational partner. This phenomenon highlighted an intriguing aspect of human interaction with bots: the propensity to attribute human-like characteristics to even the simplest forms of artificial intelligence.
The parallels between ELIZA and today's sophisticated bots are striking. Just as users in the 1960s were quick to ascribe human qualities to ELIZA, modern internet users can fall prey to the illusion of genuine engagement with bots that have become increasingly sophisticated. The evolving nature of these bots, whether driven by AI or less advanced scripting, has made them more adept at mimicking human interaction, blurring the lines between authentic human discourse and automated responses.
